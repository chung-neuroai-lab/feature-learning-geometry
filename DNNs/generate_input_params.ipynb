{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bef9344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pipeline_utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.getcwd()\n",
    "save_dir = \"/mnt/home/hlethi/ceph/learningGeometry_20240627\" # <- change this to your saving directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f6de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify parameter inputs\n",
    "# See `config.json` to see the supported input parameters\n",
    "# TODO: Add comments for each input parameters\n",
    "parameter_inputs = {\n",
    "    \"model_training\": {\n",
    "        \"model\": [\"VGG11\"], \n",
    "        \"task\": [\"CIFAR-10\"], # the dataset to train the model\n",
    "        \"optim\": [\"SGD\"],\n",
    "        \"lr\": [1.0], # the learning rate\n",
    "        \"criterion\": [\"mse\"], # the loss function\n",
    "        \"num_epoch\": [101], # measure statistics at epoch 0 and train 100 epochs. Set to 10001 if `use_step=True`\n",
    "        \"save_folder\": [save_dir],\n",
    "        \"precision\": [\"double\"], # whether to use \"float\" (float-32) or \"double\" (float-64). For lazy training, need to use `double` precision\n",
    "        \"alpha\": [1.0, 1.5, 2.0, 3.0, 5.0, 7.5, 10.0, 15.0, 30.0, 50.0, 75.0, 100.0], # the scaling factor `alpha`\n",
    "        \"gain\": [1.0],\n",
    "        \"decay\": [0.0], # weight decay. See `torch.optim.SGD`\n",
    "        \"useStep\": [False], # whether `num_epoch` would stand for number of epochs or number of gradient steps\n",
    "        \"seed\": [7, 13, 17, 37, 47], # random seed to initialize the model's weight\n",
    "        },\n",
    "    \"feature_analysis\": {\n",
    "        \"layers\": [[\"view\"]], # names of the layers to extract features from\n",
    "        \"sampleFunc\": [\"random\"], # name of the sample function to sample from the dataset\n",
    "        \"numSmpl\": [50], # number of samples for each class\n",
    "        \"numCls\": [10], # number of classes\n",
    "        \"fsData\": [\"CIFAR-10\"], # the dataset to extract features\n",
    "        \"subSeed\": [1, 4, 18, 27, 29, 49, 64, 82, 90, 98], # random seed for sampling\n",
    "        \"lastEpoch\": [False], # whether to analyze model checkpoints of all epoch or only the last epoch\n",
    "        \"saveFeature\": [False], # whether to save the extracted features\n",
    "        \"runAnalysis\": [True], # whether to run the analysis\n",
    "    },\n",
    "    \"linear_probe\": {\n",
    "        \"fsData\": [\"CIFAR-100\"],\n",
    "        \"lastEpoch\": [True],\n",
    "        \"sampleFunc\": [\"random\"],\n",
    "        \"numSmpl\": [50],\n",
    "        \"numCls\": [10],\n",
    "        \"layer\": [\"view\"],\n",
    "        \"runCapacity\": [True], # whether to run capacity analysis\n",
    "        \"runLinearProbe\": [True], # whether to run linear probe analysis\n",
    "        \"subSeed\": [1, 4, 18, 27, 29, 49, 64, 82, 90, 98],\n",
    "    },\n",
    "    \"eval_corrupt\": {\n",
    "        \"fsData\": [[\"gaussian_noise\"], [\"defocus_blur\"], [\"frost\"], [\"brightness\"], [\"pixelate\"], [\"shot_noise\"], [\"zoom_blur\"], [\"jpeg_compression\"], [\"impulse_noise\"], [\"glass_blur\"], [\"motion_blur\"], [\"snow\"], [\"fog\"], [\"contrast\"], [\"elastic_transform\"]],\n",
    "        \"sampleFunc\": [\"random\"],\n",
    "        \"numSmpl\": [50],\n",
    "        \"numCls\": [10],\n",
    "        \"layer\": [\"view\"],\n",
    "        \"runCapacity\": [True],\n",
    "        \"runEvalCorrupt\": [True], # whether to run the evaluation on corrupted dataset\n",
    "        \"corruptLevels\": [[1, 2, 3, 4, 5]], # corrupt levels of the dataset. See CIFAR-10C description in https://github.com/hendrycks/robustness\n",
    "        \"lastEpoch\": [True],\n",
    "        \"subSeed\": [1, 4, 18, 27, 29, 49, 64, 82, 90, 98],\n",
    "    },\n",
    "    \"kernels\": {\n",
    "        \"sampleFunc\": [\"random\"],\n",
    "        \"numSmpl\": [50],\n",
    "        \"numCls\": [10],\n",
    "        \"fsData\": [\"CIFAR-10\"],\n",
    "        \"lastEpoch\": [False],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb13a50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step model_training: Generated a list of 60 parameters!\n",
      "Step feature_analysis: Generated a list of 600 parameters!\n"
     ]
    }
   ],
   "source": [
    "# Generate parameter list\n",
    "parameter_list = pipeline_utils.generate_parameter_pipeline(parameter_inputs, \"standard\")\n",
    "for step in parameter_list:\n",
    "    print(f\"Step {step}: Generated a list of {len(parameter_list[step])} parameters!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee00111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save parameter list to json file at params/params_test.json\n"
     ]
    }
   ],
   "source": [
    "# Save parameter list into json file\n",
    "filename = \"params/params_test.json\"\n",
    "json.dump(parameter_list, open(filename, \"w\"))\n",
    "print(f\"Save parameter list to json file at {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22327a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step model_training: Job array length: 0-14\n",
      "Step feature_analysis: Job array length: 0-149\n"
     ]
    }
   ],
   "source": [
    "n_thread = 4\n",
    "for step in parameter_list:\n",
    "    num_jobs = len(parameter_list[step])\n",
    "    job_array_length = (num_jobs // n_thread) - 1 if num_jobs % n_thread == 0 else num_jobs // n_thread\n",
    "    print(f\"Step {step}: Job array length: 0-{job_array_length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlGeometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
